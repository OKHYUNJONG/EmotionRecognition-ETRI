{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel, AutoConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Parameters\n",
    "fold = 0\n",
    "model_name = 'klue/roberta-base'\n",
    "BATCH_SIZE =64\n",
    "MAX_LEN =256\n",
    "EPOCHS = 30\n",
    "set_lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [['Sess01','Sess02','Sess03','Sess04','Sess05','Sess06','Sess07','Sess08'],\n",
    "['Sess09','Sess10','Sess11','Sess12','Sess13','Sess14','Sess15','Sess16'],\n",
    "['Sess17','Sess18','Sess19','Sess20','Sess21','Sess22','Sess23','Sess24'],\n",
    "['Sess25','Sess26','Sess27','Sess28','Sess29','Sess30','Sess31','Sess32'],\n",
    "['Sess33','Sess34','Sess35','Sess36','Sess37','Sess38','Sess39','Sess40']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['neutral',\n",
    "    'angry',\n",
    "    'disgust',\n",
    "    'fear',\n",
    "    'happy',\n",
    "    'sad',\n",
    "    'surprise']\n",
    "df = pd.read_csv('/workspace/ETRI/new_data.csv')\n",
    "df = df[['Numb','Segment ID','Total Evaluation','text','max_count'] + targets]\n",
    "mapping_info = {\"neutral\":0,\"angry\":1,\"disgust\":2,\"fear\":3,\"happy\":4,\"sad\":5,\"surprise\":6}\n",
    "df['target'] = df['Total Evaluation'].map(mapping_info)\n",
    "\n",
    "s1 = re.compile('\\n')\n",
    "\n",
    "def remove_characters(sentence, lower=True):\n",
    "    sentence = s1.sub(' ', str(sentence))\n",
    "    if lower:\n",
    "        sentence = sentence.lower()\n",
    "    return sentence\n",
    "\n",
    "df['text'] = df['text'].map(remove_characters)\n",
    "df['not_neutral'] = 1 - df['neutral']\n",
    "\n",
    "test_list = '|'.join(folds[fold])\n",
    "train =df[df['Segment ID'].str.contains(test_list) == False]\n",
    "train = train.reset_index(drop=True)\n",
    "valid = df[df['Segment ID'].str.contains(test_list)]\n",
    "valid= valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "  def __init__(self, subjects, df, tokenizer, max_len):\n",
    "    self.subjects = subjects\n",
    "    self.df = df\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  def __len__(self):\n",
    "    return len(self.subjects)\n",
    "  def __getitem__(self, item):\n",
    "    subject = str(self.subjects[item])\n",
    "    target = self.df.loc[item,['neutral','not_neutral']].values.astype('float')\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      subject,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding = 'max_length',\n",
    "      truncation = True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "    return {\n",
    "      'subject_text': subject,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.float32)\n",
    "    }\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size, shuffle_=False, valid=False):\n",
    "  ds = SentimentDataset(\n",
    "    subjects=df.text.to_numpy(),\n",
    "    df=df,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4,\n",
    "    shuffle = shuffle_\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_review_acc(pred, label):\n",
    "    _, idx = pred.max(1)\n",
    "    \n",
    "    acc = torch.eq(idx, label).sum().item() / idx.size()[0] \n",
    "    x = label.cpu().numpy()\n",
    "    y = idx.cpu().numpy()\n",
    "    f1_acc = f1_score(x, y, average='macro')\n",
    "    return acc,f1_acc\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "train_data_loader = create_data_loader(train, tokenizer, MAX_LEN, BATCH_SIZE, shuffle_=True)\n",
    "valid_data_loader = create_data_loader(valid, tokenizer, MAX_LEN, 1, valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = AutoModel.from_pretrained(model_name)\n",
    "    self.drop = nn.Dropout(p=0.1)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "    def get_cls(target_size= n_classes):\n",
    "      return nn.Sequential(\n",
    "          nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size),\n",
    "          nn.LayerNorm(self.bert.config.hidden_size),\n",
    "          nn.Dropout(p = 0.1),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(self.bert.config.hidden_size, target_size),\n",
    "      )  \n",
    "    self.cls = get_cls(n_classes)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      return_dict=False\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "\n",
    "    out = self.cls(output)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = SentimentClassifier(n_classes=2).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=set_lr)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=int(total_steps*0.1),\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "nSamples = train.target.value_counts().sort_index().tolist()\n",
    "num = 0\n",
    "for target in targets:\n",
    "    nSamples[num] *=train[target].mean()\n",
    "    num +=1\n",
    "    \n",
    "normedWeights = [1 - (x / sum(nSamples)) for x in nSamples]\n",
    "for i in range(2,len(normedWeights)):\n",
    "  normedWeights[1] += normedWeights[i]\n",
    "normedWeights = normedWeights[:2]\n",
    "normedWeights = torch.FloatTensor(normedWeights).to(device)\n",
    "\n",
    "\n",
    "loss_fn = nn.MultiLabelSoftMarginLoss(weight=normedWeights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n",
    "\n",
    "  batch_time = AverageMeter()     \n",
    "  data_time = AverageMeter()      \n",
    "  losses = AverageMeter()         \n",
    "  accuracies = AverageMeter()\n",
    "  f1_accuracies = AverageMeter()\n",
    "  \n",
    "  sent_count = AverageMeter()   \n",
    "    \n",
    "\n",
    "  start = end = time.time()\n",
    "\n",
    "  model = model.train()\n",
    "  correct_predictions = 0\n",
    "  for step,d in enumerate(data_loader):\n",
    "    data_time.update(time.time() - end)\n",
    "    batch_size = d[\"input_ids\"].size(0) \n",
    "\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "    _, targets_max = torch.max(targets, dim=1)\n",
    "    correct_predictions += torch.sum(preds == targets_max)\n",
    "    losses.update(loss.item(), batch_size)\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "\n",
    "    sent_count.update(batch_size)\n",
    "    if step % 50 == 0 or step == (len(data_loader)-1):\n",
    "                acc,f1_acc = calc_review_acc(outputs, targets_max)\n",
    "                accuracies.update(acc, batch_size)\n",
    "                f1_accuracies.update(f1_acc, batch_size)\n",
    "\n",
    "                \n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.val:.3f}({loss.avg:.3f}) '\n",
    "                      'Acc: {acc.val:.3f}({acc.avg:.3f}) '   \n",
    "                      'f1_Acc: {f1_acc.val:.3f}({f1_acc.avg:.3f}) '           \n",
    "                      'sent/s {sent_s:.0f} '\n",
    "                      .format(\n",
    "                      epoch, step+1, len(data_loader),\n",
    "                      data_time=data_time, loss=losses,\n",
    "                      acc=accuracies,\n",
    "                      f1_acc=f1_accuracies,\n",
    "                      remain=timeSince(start, float(step+1)/len(data_loader)),\n",
    "                      sent_s=sent_count.avg/batch_time.avg\n",
    "                      ))\n",
    "\n",
    "  return correct_predictions.double() / n_examples, losses.avg\n",
    "\n",
    "def validate(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n",
    "  model = model.eval()\n",
    "  losses = []\n",
    "  outputs_arr = []\n",
    "  preds_arr = []\n",
    "  targets_max_arr = []\n",
    "  correct_predictions = 0\n",
    "  for d in tqdm(data_loader):\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    outputs_arr.append(outputs.cpu().detach().numpy()[0])\n",
    "    preds_arr.append(preds.cpu().numpy())\n",
    "    \n",
    "    loss = loss_fn(outputs, targets)\n",
    "    _, targets_max = torch.max(targets, dim=1)\n",
    "    correct_predictions += torch.sum(preds == targets_max)\n",
    "    targets_max_arr.append(targets_max.cpu().numpy())\n",
    "    losses.append(loss.item())\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses), outputs_arr, preds_arr, targets_max_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  print('-' * 10)\n",
    "  print(f'Epoch {epoch}/{EPOCHS-1}')\n",
    "  print('-' * 10)\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    len(train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "  print(\"\")\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_acc, validate_loss, outputs_arr, preds_arr, targets_max_arr= validate(\n",
    "    model,\n",
    "    valid_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    len(valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf = pd.DataFrame()\n",
    "k = 0\n",
    "for i in preds_arr:\n",
    "    tempdf.loc[k,'pred'] = i[0]\n",
    "    k +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/workspace/ETRI/new_data.csv')\n",
    "df = df[['Numb','Segment ID','Total Evaluation','text','max_count'] + targets]\n",
    "mapping_info = {\"neutral\":0,\"angry\":1,\"disgust\":2,\"fear\":3,\"happy\":4,\"sad\":5,\"surprise\":6}\n",
    "df['target'] = df['Total Evaluation'].map(mapping_info)\n",
    "df['text'] = df['text'].map(remove_characters)\n",
    "test_list = '|'.join(folds[fold])\n",
    "train =df[df['Segment ID'].str.contains(test_list) == False]\n",
    "valid = df[df['Segment ID'].str.contains(test_list)]\n",
    "train = train[train['Total Evaluation'].str.contains('neutral') == False]\n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "  def __init__(self, subjects, df, tokenizer, max_len):\n",
    "    self.subjects = subjects\n",
    "    self.df = df\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  def __len__(self):\n",
    "    return len(self.subjects)\n",
    "  def __getitem__(self, item):\n",
    "    subject = str(self.subjects[item])\n",
    "    target = self.df.iloc[item,5:-1].values.astype('float')\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      subject,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding = 'max_length',\n",
    "      truncation = True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "    return {\n",
    "      'subject_text': subject,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.float32)\n",
    "    }\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size, shuffle_=False, valid=False):\n",
    "  ds = SentimentDataset(\n",
    "    subjects=df.text.to_numpy(),\n",
    "    df=df,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4,\n",
    "    shuffle = shuffle_\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentClassifier(n_classes=7).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=set_lr)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=int(total_steps*0.1),\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "nSamples = [0] + train.target.value_counts().sort_index().tolist()\n",
    "num = 0\n",
    "for target in targets:\n",
    "    nSamples[num] *=train[target].mean()\n",
    "    num +=1\n",
    "    \n",
    "normedWeights = [1 - (x / sum(nSamples)) for x in nSamples]\n",
    "normedWeights = torch.FloatTensor(normedWeights).to(device)\n",
    "\n",
    "\n",
    "loss_fn = nn.MultiLabelSoftMarginLoss(weight=normedWeights).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "train_data_loader = create_data_loader(train, tokenizer, MAX_LEN, BATCH_SIZE, shuffle_=True)\n",
    "valid_data_loader = create_data_loader(valid, tokenizer, MAX_LEN, 1, valid=True)",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  print('-' * 10)\n",
    "  print(f'Epoch {epoch}/{EPOCHS-1}')\n",
    "  print('-' * 10)\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    len(train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "  print(\"\")\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_acc, validate_loss, outputs_arr, preds_arr, targets_max_arr= validate(\n",
    "    model,\n",
    "    valid_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    len(valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf2 = pd.DataFrame()\n",
    "k = 0\n",
    "for i in preds_arr:\n",
    "    tempdf2.loc[k,'pred'] = i[0]\n",
    "    k +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tempdf)):\n",
    "    if tempdf.loc[i,'pred'] == 1:\n",
    "        tempdf.loc[i,'pred'] = tempdf2.loc[i,\"pred\"] + 1\n",
    "mapping_info = {\"neutral\":0,\"angry\":1,\"disgust\":2,\"fear\":3,\"happy\":4,\"sad\":5,\"surprise\":6}\n",
    "df['target'] = df['Total Evaluation'].map(mapping_info)\n",
    "\n",
    "test_list = '|'.join(folds[fold])\n",
    "train =df[df['Segment ID'].str.contains(test_list) == False]\n",
    "valid = df[df['Segment ID'].str.contains(test_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = valid['target'].to_list()\n",
    "y = tempdf['pred'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y, X, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y, X, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(y,X)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

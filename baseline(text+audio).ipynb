{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel, AutoConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "import IPython.display as ipd\n",
    "from transformers import AutoConfig, Wav2Vec2Processor\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import (\n",
    "    Wav2Vec2PreTrainedModel,\n",
    "    Wav2Vec2Model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Parameters\n",
    "fold = 0\n",
    "model_name = 'klue/roberta-base'\n",
    "BATCH_SIZE =64\n",
    "MAX_LEN =256\n",
    "EPOCHS = 30\n",
    "set_lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os \n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/workspace/ETRI/new_data.csv')\n",
    "df = df[['Numb','Segment ID','Total Evaluation','text','max_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_info = {\"neutral\":0,\"angry\":1,\"disgust\":2,\"fear\":3,\"happy\":4,\"sad\":5,\"surprise\":6}\n",
    "df['target'] = df['Total Evaluation'].map(mapping_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "s1 = re.compile('\\n')\n",
    "s1 = re.compile('\\n')\n",
    "\n",
    "def remove_characters(sentence, lower=True):\n",
    "    sentence = s1.sub(' ', str(sentence))\n",
    "    if lower:\n",
    "        sentence = sentence.lower()\n",
    "    return sentence\n",
    "\n",
    "df['text'] = df['text'].map(remove_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_dir = '/workspace/ETRI/KEMDy20/wav/'\n",
    "for i in range(len(df)):\n",
    "    SegmentID = df.iloc[i,1]\n",
    "    tmp_dir = wav_dir + \"Session\" + SegmentID[4:6] +\"/\" + SegmentID + \".wav\"\n",
    "    df.loc[i,'wav_dir'] = tmp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [['Sess01','Sess02','Sess03','Sess04','Sess05','Sess06','Sess07','Sess08'],\n",
    "['Sess09','Sess10','Sess11','Sess12','Sess13','Sess14','Sess15','Sess16'],\n",
    "['Sess17','Sess18','Sess19','Sess20','Sess21','Sess22','Sess23','Sess24'],\n",
    "['Sess25','Sess26','Sess27','Sess28','Sess29','Sess30','Sess31','Sess32'],\n",
    "['Sess33','Sess34','Sess35','Sess36','Sess37','Sess38','Sess39','Sess40']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = '|'.join(folds[fold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[df['Segment ID'].str.contains(test_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =df[df['Segment ID'].str.contains(test_list) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 7\n",
    "input_column = \"wav_dir\"\n",
    "output_column = \"Total Evaluation\"\n",
    "\n",
    "model_name_or_path = \"facebook/wav2vec2-base-960h\"\n",
    "pooling_mode = \"mean\"\n",
    "\n",
    "audio_config = AutoConfig.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    finetuning_task=\"wav2vec2_clf\",\n",
    ")\n",
    "setattr(audio_config, 'pooling_mode', pooling_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target sampling rate: 16000\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(model_name_or_path,)\n",
    "target_sampling_rate = processor.feature_extractor.sampling_rate\n",
    "print(f\"The target sampling rate: {target_sampling_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(path):\n",
    "    speech_array, sampling_rate = torchaudio.load(path)\n",
    "    resampler = torchaudio.transforms.Resample(sampling_rate, target_sampling_rate)\n",
    "    speech = resampler(speech_array).squeeze().numpy()\n",
    "    input_values = processor(speech, sampling_rate=sampling_rate, return_tensors=\"pt\").input_values\n",
    "    return input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "  def __init__(self, subjects, targets, tokenizer, max_len,wav_dir,max_wv_len):\n",
    "    self.subjects = subjects\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "    self.wav_dir = wav_dir\n",
    "    self.max_wv_len = max_wv_len\n",
    "  def __len__(self):\n",
    "    return len(self.subjects)\n",
    "  def __getitem__(self, item):\n",
    "    subject = str(self.subjects[item])\n",
    "    target = self.targets[item]\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      subject,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding = 'max_length',\n",
    "      truncation = True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    wav_data = speech_file_to_array_fn(self.wav_dir[item])\n",
    "    if wav_data.size(-1) > self.max_wv_len:\n",
    "      wav_data = wav_data[:, :self.max_wv_len]\n",
    "    else:\n",
    "      k = self.max_wv_len // wav_data.size(-1)\n",
    "      tmp = torch.zeros(self.max_wv_len - k * wav_data.size(-1)).unsqueeze(0)\n",
    "      tmp2 = wav_data\n",
    "      for i in range(k-1):\n",
    "        wav_data = torch.cat([wav_data,tmp2], dim=1) \n",
    "      wav_data = torch.cat([wav_data,tmp], dim=1) \n",
    "\n",
    "    return {\n",
    "      'subject_text': subject,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long),\n",
    "      'wav_data': wav_data.flatten(),\n",
    "    }\n",
    "def create_data_loader(df, tokenizer, max_len, max_wv_len, batch_size, shuffle_=False, valid=False):\n",
    "  ds = SentimentDataset(\n",
    "    subjects=df.text.to_numpy(),\n",
    "    targets=df.target.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len,\n",
    "    wav_dir=df.wav_dir.to_numpy(),\n",
    "    max_wv_len = max_wv_len,\n",
    "  )\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4,\n",
    "    shuffle = shuffle_\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_review_acc(pred, label):\n",
    "    _, idx = pred.max(1)\n",
    "    \n",
    "    acc = torch.eq(idx, label).sum().item() / idx.size()[0] \n",
    "    x = label.cpu().numpy()\n",
    "    y = idx.cpu().numpy()\n",
    "    f1_acc = f1_score(x, y, average='macro')\n",
    "    return acc,f1_acc\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'klue/roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "BATCH_SIZE =64\n",
    "MAX_LEN =196\n",
    "MAX_WV_LEN = 4 * 16000\n",
    "train_data_loader = create_data_loader(train, tokenizer, MAX_LEN, MAX_WV_LEN, BATCH_SIZE, shuffle_=True)\n",
    "test_data_loader = create_data_loader(test, tokenizer, MAX_LEN, MAX_WV_LEN, 1, valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "  def __init__(self, n_classes,audio_config):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = AutoModel.from_pretrained(model_name)\n",
    "    self.drop = nn.Dropout(p=0.1)\n",
    "    self.audio_config = audio_config\n",
    "    self.pooling_mode = audio_config.pooling_mode\n",
    "    self.wav2vec2 = Wav2Vec2Model(audio_config)\n",
    "    def get_cls(target_size= n_classes):\n",
    "      return nn.Sequential(\n",
    "          nn.Linear(self.bert.config.hidden_size + self.audio_config.hidden_size, self.bert.config.hidden_size + self.audio_config.hidden_size),\n",
    "          nn.LayerNorm(self.bert.config.hidden_size + self.audio_config.hidden_size),\n",
    "          nn.Dropout(p = 0.1),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(self.bert.config.hidden_size + self.audio_config.hidden_size, target_size),\n",
    "      )  \n",
    "    self.cls = get_cls(n_classes)\n",
    "\n",
    "\n",
    "\n",
    "  def freeze_feature_extractor(self):\n",
    "      self.wav2vec2.feature_extractor._freeze_parameters()\n",
    "\n",
    "  def merged_strategy(\n",
    "          self,\n",
    "          hidden_states,\n",
    "          mode=\"mean\"\n",
    "  ):\n",
    "      if mode == \"mean\":\n",
    "          outputs = torch.mean(hidden_states, dim=1)\n",
    "      elif mode == \"sum\":\n",
    "          outputs = torch.sum(hidden_states, dim=1)\n",
    "      elif mode == \"max\":\n",
    "          outputs = torch.max(hidden_states, dim=1)[0]\n",
    "      else:\n",
    "          raise Exception(\n",
    "              \"The pooling method hasn't been defined! Your pooling mode must be one of these ['mean', 'sum', 'max']\")\n",
    "\n",
    "      return outputs\n",
    "\n",
    "  def forward(self, input_ids, attention_mask,input_values,\n",
    "            audio_attention_mask=None,\n",
    "            output_attentions=None,\n",
    "            output_hidden_states=None,\n",
    "            return_dict=None,):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      return_dict=False\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "\n",
    "    return_dict = return_dict if return_dict is not None else self.audio_config.use_return_dict\n",
    "    output2 = self.wav2vec2(\n",
    "            input_values,\n",
    "            attention_mask=audio_attention_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "    hidden_states = output2[0]\n",
    "    hidden_states = self.merged_strategy(hidden_states, mode=self.pooling_mode)\n",
    "\n",
    "    output2 = self.drop(hidden_states)\n",
    "\n",
    "    output = torch.cat([output,output2],1) \n",
    "    out = self.cls(output)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "EPOCHS = 20\n",
    "model = SentimentClassifier(n_classes=7,audio_config = audio_config).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=set_lr)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=int(total_steps*0.1),\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "nSamples = train.target.value_counts().sort_index().tolist()\n",
    "normedWeights = [1 - (x / sum(nSamples)) for x in nSamples]\n",
    "normedWeights = torch.FloatTensor(normedWeights).to(device)\n",
    "#loss_fn = nn.CrossEntropyLoss(normedWeights).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n",
    "\n",
    "  batch_time = AverageMeter()     \n",
    "  data_time = AverageMeter()      \n",
    "  losses = AverageMeter()         \n",
    "  accuracies = AverageMeter()\n",
    "  f1_accuracies = AverageMeter()\n",
    "  \n",
    "  sent_count = AverageMeter()   \n",
    "    \n",
    "\n",
    "  start = end = time.time()\n",
    "\n",
    "  model = model.train()\n",
    "  correct_predictions = 0\n",
    "  for step,d in enumerate(data_loader):\n",
    "    data_time.update(time.time() - end)\n",
    "    batch_size = d[\"input_ids\"].size(0) \n",
    "    wav_data = d[\"wav_data\"].to(device)\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      input_values=wav_data,\n",
    "    )\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.update(loss.item(), batch_size)\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "\n",
    "    sent_count.update(batch_size)\n",
    "    if step % 50 == 0 or step == (len(data_loader)-1):\n",
    "                acc,f1_acc = calc_review_acc(outputs, targets)\n",
    "                accuracies.update(acc, batch_size)\n",
    "                f1_accuracies.update(f1_acc, batch_size)\n",
    "\n",
    "                \n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.val:.3f}({loss.avg:.3f}) '\n",
    "                      'Acc: {acc.val:.3f}({acc.avg:.3f}) '   \n",
    "                      'f1_Acc: {f1_acc.val:.3f}({f1_acc.avg:.3f}) '           \n",
    "                      'sent/s {sent_s:.0f} '\n",
    "                      .format(\n",
    "                      epoch, step+1, len(data_loader),\n",
    "                      data_time=data_time, loss=losses,\n",
    "                      acc=accuracies,\n",
    "                      f1_acc=f1_accuracies,\n",
    "                      remain=timeSince(start, float(step+1)/len(data_loader)),\n",
    "                      sent_s=sent_count.avg/batch_time.avg\n",
    "                      ))\n",
    "\n",
    "  return correct_predictions.double() / n_examples, losses.avg\n",
    "\n",
    "def validate(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n",
    "  model = model.eval()\n",
    "  losses = []\n",
    "  outputs_arr = []\n",
    "  preds_arr = []\n",
    "  targets_arr = []\n",
    "  correct_predictions = 0\n",
    "  for d in tqdm(data_loader):\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    wav_data = d[\"wav_data\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      input_values=wav_data,\n",
    "    )\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    outputs_arr.append(outputs.cpu().detach().numpy()[0])\n",
    "    preds_arr.append(preds.cpu().numpy())\n",
    "    \n",
    "    loss = loss_fn(outputs, targets)\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    targets_arr.append(targets.cpu().numpy())\n",
    "    losses.append(loss.item())\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses), outputs_arr, preds_arr, targets_arr\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 0/19\n",
      "----------\n",
      "Epoch: [0][1/168] Data 0.388 (0.388) Elapsed 0m 5s (remain 15m 24s) Loss: 1.876(1.876) Acc: 0.125(0.125) f1_Acc: 0.042(0.042) sent/s 12 \n",
      "Epoch: [0][51/168] Data 0.004 (0.012) Elapsed 0m 42s (remain 1m 36s) Loss: 0.638(1.147) Acc: 0.844(0.484) f1_Acc: 0.183(0.113) sent/s 78 \n",
      "Epoch: [0][101/168] Data 0.004 (0.008) Elapsed 1m 18s (remain 0m 52s) Loss: 0.593(0.840) Acc: 0.844(0.604) f1_Acc: 0.183(0.136) sent/s 82 \n",
      "Epoch: [0][151/168] Data 0.004 (0.007) Elapsed 1m 55s (remain 0m 13s) Loss: 0.571(0.718) Acc: 0.844(0.664) f1_Acc: 0.153(0.140) sent/s 83 \n",
      "Epoch: [0][168/168] Data 0.004 (0.007) Elapsed 2m 9s (remain 0m 0s) Loss: 0.404(0.689) Acc: 0.879(0.704) f1_Acc: 0.305(0.171) sent/s 83 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:17<00:00, 19.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.689118568555128 accuracy 0.8181648985669087\n",
      "validate loss 0.36044301031039416 accuracy 0.9072164948453608\n",
      "validate f1-score:  0.2293595862836857\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 1/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1/168] Data 0.453 (0.453) Elapsed 0m 1s (remain 4m 0s) Loss: 0.630(0.630) Acc: 0.844(0.844) f1_Acc: 0.255(0.255) sent/s 45 \n",
      "Epoch: [1][51/168] Data 0.004 (0.014) Elapsed 0m 38s (remain 1m 27s) Loss: 0.449(0.427) Acc: 0.891(0.867) f1_Acc: 0.308(0.282) sent/s 86 \n",
      "Epoch: [1][101/168] Data 0.004 (0.009) Elapsed 1m 14s (remain 0m 49s) Loss: 0.328(0.422) Acc: 0.875(0.870) f1_Acc: 0.385(0.316) sent/s 87 \n",
      "Epoch: [1][151/168] Data 0.004 (0.008) Elapsed 1m 51s (remain 0m 12s) Loss: 0.244(0.424) Acc: 0.922(0.883) f1_Acc: 0.340(0.322) sent/s 87 \n",
      "Epoch: [1][168/168] Data 0.004 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.324(0.425) Acc: 0.897(0.885) f1_Acc: 0.519(0.358) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:18<00:00, 19.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.42512929782884296 accuracy 0.8831193002047274\n",
      "validate loss 0.32120578646363585 accuracy 0.9171575846833578\n",
      "validate f1-score:  0.22865605844959255\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 2/19\n",
      "----------\n",
      "Epoch: [2][1/168] Data 0.451 (0.451) Elapsed 0m 1s (remain 3m 18s) Loss: 0.510(0.510) Acc: 0.844(0.844) f1_Acc: 0.262(0.262) sent/s 54 \n",
      "Epoch: [2][51/168] Data 0.005 (0.014) Elapsed 0m 37s (remain 1m 27s) Loss: 0.394(0.380) Acc: 0.875(0.859) f1_Acc: 0.419(0.341) sent/s 86 \n",
      "Epoch: [2][101/168] Data 0.004 (0.010) Elapsed 1m 14s (remain 0m 49s) Loss: 0.365(0.379) Acc: 0.891(0.870) f1_Acc: 0.312(0.331) sent/s 86 \n",
      "Epoch: [2][151/168] Data 0.004 (0.008) Elapsed 1m 51s (remain 0m 12s) Loss: 0.378(0.364) Acc: 0.859(0.867) f1_Acc: 0.243(0.309) sent/s 86 \n",
      "Epoch: [2][168/168] Data 0.006 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.359(0.364) Acc: 0.879(0.869) f1_Acc: 0.251(0.298) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:19<00:00, 19.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3643220168362111 accuracy 0.889819467708915\n",
      "validate loss 0.30679449361227096 accuracy 0.9120029455081001\n",
      "validate f1-score:  0.2362752362752363\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 3/19\n",
      "----------\n",
      "Epoch: [3][1/168] Data 0.425 (0.425) Elapsed 0m 1s (remain 3m 15s) Loss: 0.222(0.222) Acc: 0.906(0.906) f1_Acc: 0.521(0.521) sent/s 55 \n",
      "Epoch: [3][51/168] Data 0.005 (0.013) Elapsed 0m 38s (remain 1m 27s) Loss: 0.378(0.297) Acc: 0.875(0.891) f1_Acc: 0.319(0.420) sent/s 86 \n",
      "Epoch: [3][101/168] Data 0.004 (0.009) Elapsed 1m 14s (remain 0m 49s) Loss: 0.121(0.297) Acc: 0.953(0.911) f1_Acc: 0.591(0.477) sent/s 86 \n",
      "Epoch: [3][151/168] Data 0.005 (0.008) Elapsed 1m 52s (remain 0m 12s) Loss: 0.281(0.297) Acc: 0.906(0.910) f1_Acc: 0.321(0.438) sent/s 86 \n",
      "Epoch: [3][168/168] Data 0.004 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.188(0.297) Acc: 0.948(0.917) f1_Acc: 0.886(0.521) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:21<00:00, 19.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.29688449194261357 accuracy 0.9011725293132329\n",
      "validate loss 0.28670267105870295 accuracy 0.9120029455081001\n",
      "validate f1-score:  0.28131667190702286\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 4/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][1/168] Data 0.446 (0.446) Elapsed 0m 1s (remain 3m 22s) Loss: 0.100(0.100) Acc: 0.984(0.984) f1_Acc: 0.960(0.960) sent/s 53 \n",
      "Epoch: [4][51/168] Data 0.004 (0.013) Elapsed 0m 37s (remain 1m 26s) Loss: 0.268(0.206) Acc: 0.891(0.938) f1_Acc: 0.224(0.592) sent/s 86 \n",
      "Epoch: [4][101/168] Data 0.005 (0.009) Elapsed 1m 14s (remain 0m 49s) Loss: 0.404(0.229) Acc: 0.875(0.917) f1_Acc: 0.358(0.514) sent/s 87 \n",
      "Epoch: [4][151/168] Data 0.005 (0.008) Elapsed 1m 51s (remain 0m 12s) Loss: 0.181(0.223) Acc: 0.922(0.918) f1_Acc: 0.504(0.511) sent/s 87 \n",
      "Epoch: [4][168/168] Data 0.004 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.127(0.224) Acc: 0.948(0.924) f1_Acc: 0.887(0.581) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:20<00:00, 19.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.22444415357322328 accuracy 0.9205285687697748\n",
      "validate loss 0.32189093813981134 accuracy 0.9024300441826215\n",
      "validate f1-score:  0.37312362063237264\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 5/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][1/168] Data 0.467 (0.467) Elapsed 0m 1s (remain 3m 27s) Loss: 0.156(0.156) Acc: 0.953(0.953) f1_Acc: 0.528(0.528) sent/s 52 \n",
      "Epoch: [5][51/168] Data 0.005 (0.014) Elapsed 0m 37s (remain 1m 26s) Loss: 0.172(0.165) Acc: 0.938(0.945) f1_Acc: 0.683(0.606) sent/s 86 \n",
      "Epoch: [5][101/168] Data 0.004 (0.010) Elapsed 1m 14s (remain 0m 49s) Loss: 0.083(0.169) Acc: 0.969(0.953) f1_Acc: 0.448(0.553) sent/s 86 \n",
      "Epoch: [5][151/168] Data 0.005 (0.008) Elapsed 1m 51s (remain 0m 12s) Loss: 0.139(0.160) Acc: 0.969(0.957) f1_Acc: 0.923(0.646) sent/s 86 \n",
      "Epoch: [5][168/168] Data 0.004 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.199(0.160) Acc: 0.948(0.955) f1_Acc: 0.906(0.694) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:18<00:00, 19.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.15957949806275856 accuracy 0.9470500651405174\n",
      "validate loss 0.38602960645705525 accuracy 0.8969072164948454\n",
      "validate f1-score:  0.3315858906856479\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 6/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][1/168] Data 0.442 (0.442) Elapsed 0m 1s (remain 3m 21s) Loss: 0.164(0.164) Acc: 0.891(0.891) f1_Acc: 0.894(0.894) sent/s 53 \n",
      "Epoch: [6][51/168] Data 0.004 (0.014) Elapsed 0m 37s (remain 1m 26s) Loss: 0.057(0.106) Acc: 0.984(0.938) f1_Acc: 0.977(0.935) sent/s 86 \n",
      "Epoch: [6][101/168] Data 0.004 (0.010) Elapsed 1m 14s (remain 0m 49s) Loss: 0.212(0.109) Acc: 0.938(0.938) f1_Acc: 0.441(0.771) sent/s 87 \n",
      "Epoch: [6][151/168] Data 0.005 (0.008) Elapsed 1m 51s (remain 0m 12s) Loss: 0.056(0.112) Acc: 0.984(0.949) f1_Acc: 0.798(0.778) sent/s 86 \n",
      "Epoch: [6][168/168] Data 0.005 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.129(0.112) Acc: 0.966(0.952) f1_Acc: 0.703(0.764) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:18<00:00, 19.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.11236401368747227 accuracy 0.9621254420249395\n",
      "validate loss 0.44197168435246414 accuracy 0.8825478645066274\n",
      "validate f1-score:  0.346115610374954\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 7/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][1/168] Data 0.406 (0.406) Elapsed 0m 1s (remain 3m 8s) Loss: 0.139(0.139) Acc: 0.953(0.953) f1_Acc: 0.695(0.695) sent/s 57 \n",
      "Epoch: [7][51/168] Data 0.004 (0.013) Elapsed 0m 37s (remain 1m 26s) Loss: 0.034(0.070) Acc: 0.984(0.969) f1_Acc: 0.664(0.679) sent/s 87 \n",
      "Epoch: [7][101/168] Data 0.005 (0.009) Elapsed 1m 14s (remain 0m 49s) Loss: 0.208(0.074) Acc: 0.938(0.958) f1_Acc: 0.635(0.665) sent/s 87 \n",
      "Epoch: [7][151/168] Data 0.005 (0.008) Elapsed 1m 51s (remain 0m 12s) Loss: 0.072(0.074) Acc: 0.984(0.965) f1_Acc: 0.815(0.702) sent/s 86 \n",
      "Epoch: [7][168/168] Data 0.007 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.132(0.076) Acc: 0.966(0.965) f1_Acc: 0.911(0.741) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:20<00:00, 19.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.07572758535577358 accuracy 0.9758049506793226\n",
      "validate loss 0.5068199166310268 accuracy 0.8888070692194403\n",
      "validate f1-score:  0.3491806784674959\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 8/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][1/168] Data 0.431 (0.431) Elapsed 0m 1s (remain 3m 21s) Loss: 0.075(0.075) Acc: 0.953(0.953) f1_Acc: 0.641(0.641) sent/s 53 \n",
      "Epoch: [8][51/168] Data 0.004 (0.014) Elapsed 0m 37s (remain 1m 26s) Loss: 0.073(0.047) Acc: 0.969(0.961) f1_Acc: 0.848(0.744) sent/s 86 \n",
      "Epoch: [8][101/168] Data 0.004 (0.010) Elapsed 1m 14s (remain 0m 49s) Loss: 0.014(0.051) Acc: 1.000(0.974) f1_Acc: 1.000(0.829) sent/s 86 \n",
      "Epoch: [8][151/168] Data 0.005 (0.008) Elapsed 1m 52s (remain 0m 12s) Loss: 0.167(0.051) Acc: 0.922(0.961) f1_Acc: 0.382(0.718) sent/s 86 \n",
      "Epoch: [8][168/168] Data 0.004 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.126(0.051) Acc: 0.966(0.962) f1_Acc: 0.912(0.754) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:19<00:00, 19.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.05147629346862843 accuracy 0.9840871021775545\n",
      "validate loss 0.5501056852510898 accuracy 0.875920471281296\n",
      "validate f1-score:  0.3821749396658664\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 9/19\n",
      "----------\n",
      "Epoch: [9][1/168] Data 0.422 (0.422) Elapsed 0m 1s (remain 3m 11s) Loss: 0.026(0.026) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 56 \n",
      "Epoch: [9][51/168] Data 0.004 (0.013) Elapsed 0m 37s (remain 1m 27s) Loss: 0.009(0.032) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [9][101/168] Data 0.004 (0.009) Elapsed 1m 14s (remain 0m 49s) Loss: 0.026(0.035) Acc: 0.984(0.995) f1_Acc: 0.978(0.993) sent/s 86 \n",
      "Epoch: [9][151/168] Data 0.009 (0.008) Elapsed 1m 52s (remain 0m 12s) Loss: 0.007(0.034) Acc: 1.000(0.996) f1_Acc: 1.000(0.995) sent/s 86 \n",
      "Epoch: [9][168/168] Data 0.004 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.071(0.035) Acc: 0.983(0.994) f1_Acc: 0.970(0.990) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:19<00:00, 19.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.0350939930663991 accuracy 0.9888330541596874\n",
      "validate loss 0.5736102638532568 accuracy 0.8928571428571428\n",
      "validate f1-score:  0.3813363924963338\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 10/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][1/168] Data 0.421 (0.421) Elapsed 0m 1s (remain 3m 16s) Loss: 0.006(0.006) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 55 \n",
      "Epoch: [10][51/168] Data 0.005 (0.013) Elapsed 0m 37s (remain 1m 26s) Loss: 0.020(0.017) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [10][101/168] Data 0.004 (0.009) Elapsed 1m 14s (remain 0m 49s) Loss: 0.009(0.021) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 87 \n",
      "Epoch: [10][151/168] Data 0.005 (0.008) Elapsed 1m 51s (remain 0m 12s) Loss: 0.010(0.021) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [10][168/168] Data 0.005 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.049(0.021) Acc: 0.983(0.997) f1_Acc: 0.924(0.986) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:19<00:00, 19.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.020657192148155902 accuracy 0.9938581797878281\n",
      "validate loss 0.6674389047890782 accuracy 0.8810751104565537\n",
      "validate f1-score:  0.36863181016704166\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 11/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [11][1/168] Data 0.445 (0.445) Elapsed 0m 1s (remain 3m 38s) Loss: 0.012(0.012) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 49 \n",
      "Epoch: [11][51/168] Data 0.004 (0.014) Elapsed 0m 38s (remain 1m 27s) Loss: 0.015(0.016) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [11][101/168] Data 0.005 (0.009) Elapsed 1m 14s (remain 0m 49s) Loss: 0.003(0.020) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [11][151/168] Data 0.005 (0.008) Elapsed 1m 52s (remain 0m 12s) Loss: 0.013(0.020) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [11][168/168] Data 0.005 (0.008) Elapsed 2m 5s (remain 0m 0s) Loss: 0.036(0.020) Acc: 0.983(0.997) f1_Acc: 0.962(0.993) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:19<00:00, 19.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.01963695268623882 accuracy 0.9945095849618463\n",
      "validate loss 0.6670324074928334 accuracy 0.8884388807069219\n",
      "validate f1-score:  0.40468466258582547\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 12/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12][1/168] Data 0.423 (0.423) Elapsed 0m 1s (remain 3m 14s) Loss: 0.035(0.035) Acc: 0.984(0.984) f1_Acc: 0.976(0.976) sent/s 55 \n",
      "Epoch: [12][51/168] Data 0.009 (0.014) Elapsed 0m 37s (remain 1m 27s) Loss: 0.002(0.014) Acc: 1.000(0.992) f1_Acc: 1.000(0.988) sent/s 86 \n",
      "Epoch: [12][101/168] Data 0.005 (0.009) Elapsed 1m 14s (remain 0m 49s) Loss: 0.028(0.014) Acc: 0.984(0.990) f1_Acc: 0.818(0.931) sent/s 87 \n",
      "Epoch: [12][151/168] Data 0.005 (0.008) Elapsed 1m 51s (remain 0m 12s) Loss: 0.001(0.013) Acc: 1.000(0.992) f1_Acc: 1.000(0.949) sent/s 86 \n",
      "Epoch: [12][168/168] Data 0.004 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.004(0.014) Acc: 1.000(0.994) f1_Acc: 1.000(0.958) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:19<00:00, 19.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.013759005907350982 accuracy 0.9960915689558906\n",
      "validate loss 0.7076337023703557 accuracy 0.8877025036818851\n",
      "validate f1-score:  0.37375441499017853\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 13/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13][1/168] Data 0.425 (0.425) Elapsed 0m 1s (remain 3m 17s) Loss: 0.000(0.000) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 55 \n",
      "Epoch: [13][51/168] Data 0.004 (0.014) Elapsed 0m 37s (remain 1m 26s) Loss: 0.000(0.010) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [13][101/168] Data 0.005 (0.010) Elapsed 1m 14s (remain 0m 49s) Loss: 0.001(0.010) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [13][151/168] Data 0.004 (0.008) Elapsed 1m 52s (remain 0m 12s) Loss: 0.001(0.011) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [13][168/168] Data 0.007 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.000(0.010) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:20<00:00, 19.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.009632485577449751 accuracy 0.9974874371859297\n",
      "validate loss 0.7475144512047741 accuracy 0.8814432989690721\n",
      "validate f1-score:  0.3578975845791333\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 14/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [14][1/168] Data 0.433 (0.433) Elapsed 0m 1s (remain 3m 17s) Loss: 0.001(0.001) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 54 \n",
      "Epoch: [14][51/168] Data 0.004 (0.013) Elapsed 0m 37s (remain 1m 27s) Loss: 0.002(0.005) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [14][101/168] Data 0.005 (0.010) Elapsed 1m 14s (remain 0m 49s) Loss: 0.003(0.006) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [14][151/168] Data 0.005 (0.008) Elapsed 1m 51s (remain 0m 12s) Loss: 0.003(0.006) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [14][168/168] Data 0.004 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.003(0.006) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:19<00:00, 19.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.005646911430490343 accuracy 0.9985110738879583\n",
      "validate loss 0.7556522320687563 accuracy 0.8832842415316642\n",
      "validate f1-score:  0.3522134936719322\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 15/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][1/168] Data 0.430 (0.430) Elapsed 0m 1s (remain 3m 20s) Loss: 0.001(0.001) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 54 \n",
      "Epoch: [15][51/168] Data 0.004 (0.014) Elapsed 0m 37s (remain 1m 26s) Loss: 0.000(0.004) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [15][101/168] Data 0.004 (0.009) Elapsed 1m 14s (remain 0m 49s) Loss: 0.003(0.004) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [15][151/168] Data 0.004 (0.008) Elapsed 1m 51s (remain 0m 12s) Loss: 0.001(0.004) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [15][168/168] Data 0.006 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.000(0.004) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:20<00:00, 19.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.004434960832579795 accuracy 0.9988833054159687\n",
      "validate loss 0.7894133729849364 accuracy 0.8792341678939617\n",
      "validate f1-score:  0.3518348432478013\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 16/19\n",
      "----------\n",
      "Epoch: [16][1/168] Data 0.433 (0.433) Elapsed 0m 1s (remain 3m 22s) Loss: 0.061(0.061) Acc: 0.984(0.984) f1_Acc: 0.980(0.980) sent/s 53 \n",
      "Epoch: [16][51/168] Data 0.004 (0.014) Elapsed 0m 37s (remain 1m 26s) Loss: 0.027(0.006) Acc: 0.984(0.984) f1_Acc: 0.980(0.980) sent/s 86 \n",
      "Epoch: [16][101/168] Data 0.004 (0.010) Elapsed 1m 14s (remain 0m 49s) Loss: 0.001(0.005) Acc: 1.000(0.990) f1_Acc: 1.000(0.987) sent/s 87 \n",
      "Epoch: [16][151/168] Data 0.005 (0.008) Elapsed 1m 51s (remain 0m 12s) Loss: 0.000(0.005) Acc: 1.000(0.992) f1_Acc: 1.000(0.990) sent/s 86 \n",
      "Epoch: [16][168/168] Data 0.004 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.016(0.005) Acc: 0.983(0.990) f1_Acc: 0.960(0.984) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:18<00:00, 19.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.0051306760146251585 accuracy 0.9983249581239532\n",
      "validate loss 0.7796842033305615 accuracy 0.8770250368188512\n",
      "validate f1-score:  0.35411618058775174\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 17/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17][1/168] Data 0.431 (0.431) Elapsed 0m 1s (remain 3m 19s) Loss: 0.001(0.001) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 54 \n",
      "Epoch: [17][51/168] Data 0.005 (0.014) Elapsed 0m 37s (remain 1m 26s) Loss: 0.001(0.001) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [17][101/168] Data 0.005 (0.010) Elapsed 1m 14s (remain 0m 49s) Loss: 0.000(0.002) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [17][151/168] Data 0.005 (0.008) Elapsed 1m 52s (remain 0m 12s) Loss: 0.002(0.002) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [17][168/168] Data 0.004 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.001(0.002) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:18<00:00, 19.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.002122973148537172 accuracy 0.999534710589987\n",
      "validate loss 0.7710434791795442 accuracy 0.8836524300441826\n",
      "validate f1-score:  0.3590533619855974\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 18/19\n",
      "----------\n",
      "Epoch: [18][1/168] Data 0.444 (0.444) Elapsed 0m 1s (remain 3m 17s) Loss: 0.001(0.001) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 54 \n",
      "Epoch: [18][51/168] Data 0.004 (0.014) Elapsed 0m 37s (remain 1m 27s) Loss: 0.000(0.002) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [18][101/168] Data 0.004 (0.009) Elapsed 1m 14s (remain 0m 49s) Loss: 0.000(0.003) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 87 \n",
      "Epoch: [18][151/168] Data 0.004 (0.008) Elapsed 1m 51s (remain 0m 12s) Loss: 0.001(0.003) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n",
      "Epoch: [18][168/168] Data 0.005 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.008(0.003) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:18<00:00, 19.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.002604080005220427 accuracy 0.9993485948259818\n",
      "validate loss 0.7664422804734462 accuracy 0.8851251840942562\n",
      "validate f1-score:  0.36618094138233637\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 19/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19][1/168] Data 0.464 (0.464) Elapsed 0m 1s (remain 3m 26s) Loss: 0.001(0.001) Acc: 1.000(1.000) f1_Acc: 1.000(1.000) sent/s 52 \n",
      "Epoch: [19][51/168] Data 0.005 (0.014) Elapsed 0m 37s (remain 1m 27s) Loss: 0.022(0.002) Acc: 0.984(0.992) f1_Acc: 0.798(0.899) sent/s 86 \n",
      "Epoch: [19][101/168] Data 0.010 (0.010) Elapsed 1m 14s (remain 0m 49s) Loss: 0.000(0.002) Acc: 1.000(0.995) f1_Acc: 1.000(0.933) sent/s 86 \n",
      "Epoch: [19][151/168] Data 0.005 (0.008) Elapsed 1m 52s (remain 0m 12s) Loss: 0.000(0.004) Acc: 1.000(0.996) f1_Acc: 1.000(0.950) sent/s 86 \n",
      "Epoch: [19][168/168] Data 0.004 (0.008) Elapsed 2m 5s (remain 0m 0s) Loss: 0.001(0.003) Acc: 1.000(0.997) f1_Acc: 1.000(0.959) sent/s 86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [02:19<00:00, 19.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.003394321558690494 accuracy 0.9988833054159687\n",
      "validate loss 0.7681011658622294 accuracy 0.8862297496318114\n",
      "validate f1-score:  0.36765774962107306\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  print('-' * 10)\n",
    "  print(f'Epoch {epoch}/{EPOCHS-1}')\n",
    "  print('-' * 10)\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer, \n",
    "    device,\n",
    "    scheduler,\n",
    "    len(train)\n",
    "  )\n",
    "  validate_acc, validate_loss, outputs_arr, preds_arr, targets_max_arr= validate(\n",
    "      model,\n",
    "      test_data_loader,\n",
    "      loss_fn,\n",
    "      optimizer,\n",
    "      device,\n",
    "      scheduler,\n",
    "      len(test)\n",
    "  )\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "  print(f'validate loss {validate_loss} accuracy {validate_acc}')\n",
    "  print(f'validate f1-score: ',f1_score(preds_arr, targets_max_arr, average='macro'))\n",
    "  print(\"\")\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36765774962107306"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(preds_arr, targets_max_arr, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8862297496318114"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(preds_arr, targets_max_arr, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8862297496318114"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(preds_arr,targets_max_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43061963116057417"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(targets_max_arr, preds_arr)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
